{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EAL7YbIqGFr"
   },
   "source": [
    "**Занятие первое**\n",
    "\n",
    "Начнем с простого. Многие знают что такое map и reduce операции, но все же для закрпеления мы их тут реализуем. Ах да, не забудем и про shuffle. Делать все будем на упрощенной задаче с word count для ознакомления с самим подходом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DBUYlacS6nb"
   },
   "source": [
    "На самом деле мы рассмптрим все в упрощенном виде, но это даст нам понимание, как можно через hadoop streaming, например, писать самописные map и reduce операции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHxuTfZ1TKc9"
   },
   "source": [
    "! mapred streaming \\\n",
    "  -input /wiki/sample.jsonl \\\n",
    "  -output /word-count \\\n",
    "  -mapper \"/opt/conda/bin/python3.6 mapper.py\" \\\n",
    "  -reducer \"/opt/conda/bin/python3.6 reducer.py\" \\\n",
    "  -file mapper.py \\\n",
    "  -file reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe2aSFz_Tgqv"
   },
   "source": [
    "Выше mapper.py и reducer.py это программы, которые выполняют одноименные операции нам потоком информации из jsonl файла, записывая ответ в файл word-count"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hGAAKrdu5d-",
    "outputId": "049b1e3f-378e-4399-a1e5-cd11557c2737",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:42.594077Z",
     "start_time": "2024-09-25T23:53:42.588978Z"
    }
   },
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "import string"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\denis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\denis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\denis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 157
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPXzd-YMtqcO"
   },
   "source": [
    "Давайте загрузим файл с текстом и посмотрим на него"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qKUCkYpBp9Lt",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:42.709727Z",
     "start_time": "2024-09-25T23:53:42.632969Z"
    }
   },
   "source": [
    "with open('spark_text.txt', 'rb') as f:\n",
    "    data = f.readlines()\n",
    "data = [text.decode() for text in data if text.decode() != '\\r\\n']    "
   ],
   "outputs": [],
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CywPTchftnqK",
    "outputId": "e6952263-6266-415d-9361-9a449fa3f5bb",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:42.734549Z",
     "start_time": "2024-09-25T23:53:42.728773Z"
    }
   },
   "source": [
    "len(data)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 159
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "0wRwGdoJ5pQs",
    "outputId": "74da6396-3a7e-4b24-a076-46d93d4537c0",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:42.779478Z",
     "start_time": "2024-09-25T23:53:42.772549Z"
    }
   },
   "source": [
    "data[1]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apache Spark has its architectural foundation in the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way.[2] The Dataframe API was released as an abstraction on top of the RDD, followed by the Dataset API. In Spark 1.x, the RDD was the primary application programming interface (API), but as of Spark 2.x use of the Dataset API is encouraged[3] even though the RDD API is not deprecated.[4][5] The RDD technology still underlies the Dataset API.[6][7]\\r\\n'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 160
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydjOU0HLwCZq"
   },
   "source": [
    "Как бы мы сделали..\n",
    "Надо немного почистить слова, а также сделать все в парадигме MapReduce. Понятно, что можно все написать проще, но мы ведь хотим понять, как это работает=)\n",
    "\n",
    "Загрузим стоп слова, очистим от них текст, приведем к нижнему регистру, всем раздадим ключи"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s-zIUslxxtyQ",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:42.847812Z",
     "start_time": "2024-09-25T23:53:42.842986Z"
    }
   },
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words = set(stop_words)"
   ],
   "outputs": [],
   "execution_count": 161
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOXxYSKI2EfQ",
    "outputId": "007979aa-8205-49e1-f75f-462568ad3f00",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:42.904551Z",
     "start_time": "2024-09-25T23:53:42.897632Z"
    }
   },
   "source": [
    "stop_words"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 162
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDK6W4MUewdv"
   },
   "source": [
    "пунктуацию тоже полезно бы удалить"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "XhrSCeUJ2MKZ",
    "outputId": "cfa3a9fd-00e8-4c2b-bc0b-fa446aa12d4c",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:42.943332Z",
     "start_time": "2024-09-25T23:53:42.937292Z"
    }
   },
   "source": [
    "string.punctuation"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 163
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R0AjYtsiv9tc",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.014175Z",
     "start_time": "2024-09-25T23:53:43.005258Z"
    }
   },
   "source": [
    "def mapper_text(text):\n",
    "    clean_text = re.sub(rf\"[{string.punctuation}]\", \"\", text)\n",
    "    words = nltk.word_tokenize(clean_text)\n",
    "    words_with_value = [(word.lower(), 1) for word in words \n",
    "                        if word not in stop_words]\n",
    "    words_with_value = sorted(words_with_value, key=lambda x:x[0])\n",
    "    return words_with_value\n",
    "\n",
    "def create_chunks(shuffled_data):\n",
    "    result = {}\n",
    "    for idx, data in shuffled_data:\n",
    "        if idx in result:\n",
    "            result[idx].append(data)\n",
    "        else:\n",
    "            result[idx] = [data]\n",
    "    return list(result.items())\n",
    "\n",
    "def shuffle_text(mapper_result, n_nodes=5):\n",
    "    shuffled_data = []\n",
    "    for key, value in mapper_result:\n",
    "        shuffled_data.append((hash(key)%n_nodes, (key, value)))\n",
    "    shuffled_data = sorted(shuffled_data, key=lambda x: x[0])\n",
    "    chunks = create_chunks(shuffled_data)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# на самом деле для reduce в жизни пишут иначе..не зря мы сортируем внутри map\n",
    "#данные по ключам. Это нужно для избавления от этапа проверки ключа и поиска\n",
    "def reduce_text(values_to_reduce):\n",
    "    result = {}\n",
    "    for key, value in values_to_reduce:\n",
    "        if key in result:\n",
    "            result[key] += 1\n",
    "        else:\n",
    "            result[key] = 1\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 164
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7qztZ0ijcqf"
   },
   "source": [
    "Проверим, что все работает\n",
    "\n",
    "Сначала map"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "133g98tQMT8I",
    "outputId": "cf08ffd4-edf6-4a86-d224-d7bb5a6c7dc3",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.061069Z",
     "start_time": "2024-09-25T23:53:43.056396Z"
    }
   },
   "source": [
    "data[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apache Spark is an open-source unified analytics engine for large-scale data processing. Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. Originally developed at the University of California, Berkeley AMPLab, the Spark codebase was later donated to the Apache Software Foundation, which has maintained it since.\\r\\n'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 165
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UpqqPnNRhCXp",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.113108Z",
     "start_time": "2024-09-25T23:53:43.109034Z"
    }
   },
   "source": [
    "map_stage = mapper_text(data[0])"
   ],
   "outputs": [],
   "execution_count": 166
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hiOXuxSsDno",
    "outputId": "df8debdd-5a1b-44c0-b635-d9b29f52f99f",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.153908Z",
     "start_time": "2024-09-25T23:53:43.149159Z"
    }
   },
   "source": [
    "map_stage"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amplab', 1),\n",
       " ('analytics', 1),\n",
       " ('apache', 1),\n",
       " ('apache', 1),\n",
       " ('berkeley', 1),\n",
       " ('california', 1),\n",
       " ('clusters', 1),\n",
       " ('codebase', 1),\n",
       " ('data', 1),\n",
       " ('data', 1),\n",
       " ('developed', 1),\n",
       " ('donated', 1),\n",
       " ('engine', 1),\n",
       " ('entire', 1),\n",
       " ('fault', 1),\n",
       " ('foundation', 1),\n",
       " ('implicit', 1),\n",
       " ('interface', 1),\n",
       " ('largescale', 1),\n",
       " ('later', 1),\n",
       " ('maintained', 1),\n",
       " ('opensource', 1),\n",
       " ('originally', 1),\n",
       " ('parallelism', 1),\n",
       " ('processing', 1),\n",
       " ('programming', 1),\n",
       " ('provides', 1),\n",
       " ('since', 1),\n",
       " ('software', 1),\n",
       " ('spark', 1),\n",
       " ('spark', 1),\n",
       " ('spark', 1),\n",
       " ('tolerance', 1),\n",
       " ('unified', 1),\n",
       " ('university', 1)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 167
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoOq2kxGl4FM"
   },
   "source": [
    "shuffle"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dLyQcJ7Xjmll",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.305875Z",
     "start_time": "2024-09-25T23:53:43.188043Z"
    }
   },
   "source": [
    "shuffle_stage = shuffle_text(map_stage, 5)"
   ],
   "outputs": [],
   "execution_count": 168
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ig2vthBFsNTm",
    "outputId": "a1436c8d-52ef-48ef-df6d-fa5d0b4c48bc",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.328010Z",
     "start_time": "2024-09-25T23:53:43.321794Z"
    }
   },
   "source": [
    "shuffle_stage"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('codebase', 1),\n",
       "   ('donated', 1),\n",
       "   ('implicit', 1),\n",
       "   ('maintained', 1),\n",
       "   ('opensource', 1),\n",
       "   ('provides', 1),\n",
       "   ('university', 1)]),\n",
       " (1,\n",
       "  [('engine', 1),\n",
       "   ('fault', 1),\n",
       "   ('foundation', 1),\n",
       "   ('largescale', 1),\n",
       "   ('parallelism', 1),\n",
       "   ('since', 1),\n",
       "   ('spark', 1),\n",
       "   ('spark', 1),\n",
       "   ('spark', 1),\n",
       "   ('unified', 1)]),\n",
       " (2,\n",
       "  [('amplab', 1),\n",
       "   ('analytics', 1),\n",
       "   ('clusters', 1),\n",
       "   ('developed', 1),\n",
       "   ('entire', 1),\n",
       "   ('later', 1),\n",
       "   ('originally', 1),\n",
       "   ('processing', 1),\n",
       "   ('software', 1)]),\n",
       " (3, [('data', 1), ('data', 1), ('programming', 1)]),\n",
       " (4,\n",
       "  [('apache', 1),\n",
       "   ('apache', 1),\n",
       "   ('berkeley', 1),\n",
       "   ('california', 1),\n",
       "   ('interface', 1),\n",
       "   ('tolerance', 1)])]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 169
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rqyNgzpl8q1"
   },
   "source": [
    "reduce"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJed4iQsll9i",
    "outputId": "72da51e1-6987-407f-eaaf-7295ed766f14",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.374296Z",
     "start_time": "2024-09-25T23:53:43.367660Z"
    }
   },
   "source": "reduce_text(shuffle_stage[4][1])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apache': 2, 'berkeley': 1, 'california': 1, 'interface': 1, 'tolerance': 1}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 170
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOuqRbx5srNh"
   },
   "source": [
    "Итак, осталось все рассчитать параллельно и собрать результаты"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5NgoQwpasxwq",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.423735Z",
     "start_time": "2024-09-25T23:53:43.419745Z"
    }
   },
   "source": [
    "from joblib import Parallel, delayed"
   ],
   "outputs": [],
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v3ogNEUhtvkD",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.464031Z",
     "start_time": "2024-09-25T23:53:43.460435Z"
    }
   },
   "source": [
    "n_nodes = 5"
   ],
   "outputs": [],
   "execution_count": 172
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rA9awfQ4RSo"
   },
   "source": [
    "Обернем в 1 функциию для удобства map и shuffle"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TItZtKEF4Qiu",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.484790Z",
     "start_time": "2024-09-25T23:53:43.480181Z"
    }
   },
   "source": [
    "def map_shuffle(text, n_nodes):\n",
    "    map_result = mapper_text(text)\n",
    "    shuffle_result = shuffle_text(map_result, n_nodes)\n",
    "    return shuffle_result"
   ],
   "outputs": [],
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WOywHRItFWD",
    "outputId": "ecaa9062-0ad2-4ce0-a3f7-abf0d4c4a774",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.536421Z",
     "start_time": "2024-09-25T23:53:43.499712Z"
    }
   },
   "source": [
    "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
    "    res = parallel(delayed(map_shuffle)(df, n_nodes) for df in data)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIfatYoXMjPW",
    "outputId": "015f407a-8909-44fa-cc49-b15b019c1eed",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.574176Z",
     "start_time": "2024-09-25T23:53:43.568140Z"
    }
   },
   "source": [
    "len(res)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 175
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EgpGGu9MknD",
    "outputId": "c9f7073a-5c00-4503-f619-dbf87112f925",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.634496Z",
     "start_time": "2024-09-25T23:53:43.627535Z"
    }
   },
   "source": [
    "res[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('analytics', 1),\n",
       "   ('clusters', 1),\n",
       "   ('codebase', 1),\n",
       "   ('implicit', 1),\n",
       "   ('later', 1),\n",
       "   ('opensource', 1),\n",
       "   ('since', 1),\n",
       "   ('university', 1)]),\n",
       " (1,\n",
       "  [('california', 1),\n",
       "   ('data', 1),\n",
       "   ('data', 1),\n",
       "   ('engine', 1),\n",
       "   ('entire', 1),\n",
       "   ('maintained', 1)]),\n",
       " (2,\n",
       "  [('developed', 1), ('donated', 1), ('largescale', 1), ('parallelism', 1)]),\n",
       " (3,\n",
       "  [('amplab', 1),\n",
       "   ('apache', 1),\n",
       "   ('apache', 1),\n",
       "   ('berkeley', 1),\n",
       "   ('fault', 1),\n",
       "   ('originally', 1),\n",
       "   ('processing', 1),\n",
       "   ('provides', 1),\n",
       "   ('unified', 1)]),\n",
       " (4,\n",
       "  [('foundation', 1),\n",
       "   ('interface', 1),\n",
       "   ('programming', 1),\n",
       "   ('software', 1),\n",
       "   ('spark', 1),\n",
       "   ('spark', 1),\n",
       "   ('spark', 1),\n",
       "   ('tolerance', 1)])]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 176
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvAYM5vA9K8N"
   },
   "source": [
    "Сделаем что-то вроде перессылки, собирая все в словари и заодно посмотрим на сколько равномерно распределлиись наши слова"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8kTLnBO24013",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.678215Z",
     "start_time": "2024-09-25T23:53:43.672687Z"
    }
   },
   "source": [
    "shuffle_stage = {i:[] for i in range(5)}\n",
    "for values in res:\n",
    "    values = dict(values)\n",
    "    for key in values.keys():\n",
    "        shuffle_stage[key].extend(values[key])"
   ],
   "outputs": [],
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9sAjyP46kUE",
    "outputId": "f9310ac8-0a73-4e5c-f594-a1670b71893c",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.731355Z",
     "start_time": "2024-09-25T23:53:43.727048Z"
    }
   },
   "source": [
    "for key in shuffle_stage.keys():\n",
    "    print(f'{key}: number of words = {len(shuffle_stage[key])}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: number of words = 364\n",
      "1: number of words = 393\n",
      "2: number of words = 352\n",
      "3: number of words = 406\n",
      "4: number of words = 406\n"
     ]
    }
   ],
   "execution_count": 178
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVEA-LZG9eEv"
   },
   "source": [
    "И последний этап - нужно сделать reduce"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5i95b8FbDboX",
    "outputId": "9c3b897f-4e05-430b-cf68-4d0861a92497",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.779316Z",
     "start_time": "2024-09-25T23:53:43.762176Z"
    }
   },
   "source": [
    "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
    "    res = parallel(delayed(reduce_text)(shuffle_stage[key]) for key in shuffle_stage.keys())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkGsGeKE7FeS",
    "outputId": "50bb92f6-8db8-426f-8a02-6a2731163adc",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.833789Z",
     "start_time": "2024-09-25T23:53:43.828681Z"
    }
   },
   "source": [
    "len(res)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8on05jYEMxUp",
    "outputId": "f0e4c915-3907-4e33-da52-f34e236ece3b",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.890125Z",
     "start_time": "2024-09-25T23:53:43.879566Z"
    }
   },
   "source": [
    "res[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analytics': 5,\n",
       " 'clusters': 1,\n",
       " 'codebase': 1,\n",
       " 'implicit': 1,\n",
       " 'later': 1,\n",
       " 'opensource': 1,\n",
       " 'since': 1,\n",
       " 'university': 1,\n",
       " '1x': 1,\n",
       " 'dataframe': 1,\n",
       " 'even': 1,\n",
       " 'items': 2,\n",
       " 'computing': 1,\n",
       " 'function': 2,\n",
       " 'limitations': 1,\n",
       " 'particular': 1,\n",
       " 'spark': 21,\n",
       " 'store': 1,\n",
       " 'memory8': 1,\n",
       " 'restricted': 2,\n",
       " 'implementation': 5,\n",
       " 'multiple': 2,\n",
       " 'learning': 7,\n",
       " 'machine': 5,\n",
       " 'magnitude': 1,\n",
       " 'training': 1,\n",
       " 'also': 4,\n",
       " 'manually': 1,\n",
       " 'native': 1,\n",
       " 'run': 6,\n",
       " 'custom': 3,\n",
       " 'kudu': 1,\n",
       " 'single': 1,\n",
       " 'usually': 1,\n",
       " 'variety': 2,\n",
       " 'application': 3,\n",
       " 'java': 2,\n",
       " 'languages': 2,\n",
       " 'nonjvm': 1,\n",
       " 'input': 1,\n",
       " 'ones': 2,\n",
       " 'parallel': 4,\n",
       " 'scala': 4,\n",
       " 'sequence': 2,\n",
       " 'available': 1,\n",
       " 'besides': 2,\n",
       " 'broadcast': 1,\n",
       " 'forms': 1,\n",
       " 'functional': 2,\n",
       " 'style': 1,\n",
       " 'argument': 1,\n",
       " 'each': 1,\n",
       " 'following': 1,\n",
       " 'item': 1,\n",
       " 'occurring': 1,\n",
       " 'set': 2,\n",
       " 'called': 2,\n",
       " 'commandline': 1,\n",
       " 'compiletime': 1,\n",
       " 'core': 3,\n",
       " 'dsl': 1,\n",
       " 'manipulate': 1,\n",
       " 'net16': 1,\n",
       " 'well': 3,\n",
       " 'minibatches': 3,\n",
       " 'thus': 1,\n",
       " 'builtin': 2,\n",
       " 'event': 2,\n",
       " 'kinesis': 1,\n",
       " 'latency': 1,\n",
       " 'minibatch': 1,\n",
       " 'process': 2,\n",
       " 'tcpip': 1,\n",
       " 'zeromq': 1,\n",
       " 'based': 1,\n",
       " 'higherlevel': 1,\n",
       " 'interface': 5,\n",
       " 'structured': 12,\n",
       " 'technology': 1,\n",
       " 'center': 1,\n",
       " 'cloud': 1,\n",
       " 'benchmarks': 1,\n",
       " 'developers': 4,\n",
       " 'due': 1,\n",
       " 'framework': 3,\n",
       " 'including': 2,\n",
       " 'mahout': 2,\n",
       " 'memorybased': 1,\n",
       " 'shipped': 1,\n",
       " 'alone': 1,\n",
       " 'attached': 1,\n",
       " 'edges': 1,\n",
       " 'full': 1,\n",
       " 'immutable': 2,\n",
       " 'mapreducestyle': 1,\n",
       " 'provides': 2,\n",
       " 'transactional': 1,\n",
       " 'software': 1,\n",
       " 'abstracts': 1,\n",
       " 'away': 1,\n",
       " 'distribute': 1,\n",
       " 'grunt': 1,\n",
       " 'key': 2,\n",
       " 'marshalling': 1,\n",
       " 'power': 1,\n",
       " 'qualities': 1,\n",
       " 'quickly': 1,\n",
       " 'sets': 1,\n",
       " 'shoulders': 1,\n",
       " 'apple': 1,\n",
       " 'deployed': 1,\n",
       " 'frameworks': 2,\n",
       " 'microsoft': 1,\n",
       " 'streaming': 4,\n",
       " 'ways': 1,\n",
       " 'driver': 1,\n",
       " 'fundamental': 1,\n",
       " 'mediate': 1,\n",
       " 'necessary': 1,\n",
       " 'worker': 1,\n",
       " 'advantage': 2,\n",
       " 'demand': 1,\n",
       " 'distributions': 1,\n",
       " 'kubernetes': 1,\n",
       " 'mean': 1,\n",
       " 'out': 1,\n",
       " 'robust': 1,\n",
       " 'swarm': 1,\n",
       " 'databricks': 2,\n",
       " 'distribution': 1,\n",
       " 'founders': 1,\n",
       " 'integrated': 1,\n",
       " 'solution': 1,\n",
       " 'standard': 1,\n",
       " 'included': 1,\n",
       " 'enterprise': 1,\n",
       " 'report': 1,\n",
       " 'contained': 1,\n",
       " 'creates': 1,\n",
       " 'efficiently': 1,\n",
       " 'engine': 1,\n",
       " 'require': 1,\n",
       " 'situations': 1,\n",
       " 'times': 2,\n",
       " 'friendliness': 1,\n",
       " 'important': 3,\n",
       " 'second': 1,\n",
       " 'comparison': 1,\n",
       " 'complexity': 1,\n",
       " 'count': 1,\n",
       " 'lines': 2,\n",
       " 'at': 1,\n",
       " 'collection': 1,\n",
       " 'aggregation': 1,\n",
       " 'buckets': 1,\n",
       " 'functionality': 1,\n",
       " 'joining': 1,\n",
       " 'nosql': 1,\n",
       " 'stores': 1,\n",
       " 'applications': 1,\n",
       " 'work': 1,\n",
       " 'sql': 9,\n",
       " 'bringing': 1,\n",
       " 'known': 1,\n",
       " 'likely': 1,\n",
       " 'python': 2,\n",
       " 'shark': 1,\n",
       " 'using': 3,\n",
       " 'connectors': 1,\n",
       " 'line': 1,\n",
       " 'simple': 1,\n",
       " 'easy': 1,\n",
       " 'imported': 1,\n",
       " 'javabased': 1,\n",
       " 'kmeans': 1,\n",
       " 'scientists': 1,\n",
       " 'swapped': 1,\n",
       " 'use': 1,\n",
       " 'networks': 1,\n",
       " 'neural': 1,\n",
       " 'pipelines': 3,\n",
       " 'operations': 1,\n",
       " 'package': 1,\n",
       " 'different': 3,\n",
       " 'gain': 1,\n",
       " 'involving': 1,\n",
       " 'needs': 1,\n",
       " 'obviously': 1,\n",
       " 'realtime': 3,\n",
       " 'storm': 1,\n",
       " 'would': 1,\n",
       " 'api': 3,\n",
       " 'batch': 2,\n",
       " 'wins': 1,\n",
       " 'a': 2,\n",
       " 'match': 1,\n",
       " 'microbatching': 2,\n",
       " 'response': 1,\n",
       " '2x': 1,\n",
       " 'create': 1,\n",
       " 'dataframes': 1,\n",
       " 'eventtime': 1,\n",
       " 'go': 1,\n",
       " 'messages': 1,\n",
       " 'streams': 1,\n",
       " 'as': 1,\n",
       " 'handle': 1,\n",
       " 'latencies': 1,\n",
       " 'low': 1,\n",
       " 'originally': 1,\n",
       " 'scheme': 1,\n",
       " 'method': 1,\n",
       " 'porting': 1,\n",
       " 'deep': 5,\n",
       " 'construct': 1,\n",
       " 'structure': 1,\n",
       " 'tensorflow': 1,\n",
       " 'tutorials': 1,\n",
       " 'basics': 1,\n",
       " 'guides': 1,\n",
       " 'heitman': 1,\n",
       " 'increasingly': 1,\n",
       " 'neanderthal': 1,\n",
       " 'science': 1,\n",
       " 'scientist': 1}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 181
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZsgvg9oEVwt"
   },
   "source": [
    "Собираем результат"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yVKdO8eAD24r",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.944539Z",
     "start_time": "2024-09-25T23:53:43.938588Z"
    }
   },
   "source": [
    "result = {}\n",
    "for partition in res:\n",
    "    for key in partition.keys():\n",
    "        if key in result:\n",
    "            result[key] += partition[key]\n",
    "        else:\n",
    "            result[key] = partition[key]"
   ],
   "outputs": [],
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUTsOJf7EtW1",
    "outputId": "067818de-4a94-4037-b4ab-ea522f5ff037",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:43.998318Z",
     "start_time": "2024-09-25T23:53:43.972625Z"
    }
   },
   "source": [
    "sorted(result.items(), key=lambda x: x[1], reverse=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark', 110),\n",
       " ('apache', 56),\n",
       " ('data', 44),\n",
       " ('streaming', 36),\n",
       " ('distributed', 23),\n",
       " ('processing', 19),\n",
       " ('sql', 17),\n",
       " ('learning', 15),\n",
       " ('also', 15),\n",
       " ('rdd', 15),\n",
       " ('api', 14),\n",
       " ('structured', 13),\n",
       " ('machine', 12),\n",
       " ('cluster', 12),\n",
       " ('hadoop', 11),\n",
       " ('interface', 10),\n",
       " ('provides', 10),\n",
       " ('rdds', 10),\n",
       " ('mapreduce', 10),\n",
       " ('core', 9),\n",
       " ('framework', 9),\n",
       " ('use', 9),\n",
       " ('graph', 9),\n",
       " ('the', 9),\n",
       " ('mllib', 9),\n",
       " ('programming', 9),\n",
       " ('application', 8),\n",
       " ('python', 8),\n",
       " ('used', 8),\n",
       " ('code', 8),\n",
       " ('support', 8),\n",
       " ('tasks', 8),\n",
       " ('run', 7),\n",
       " ('operations', 7),\n",
       " ('deep', 7),\n",
       " ('it', 7),\n",
       " ('algorithms', 7),\n",
       " ('in', 7),\n",
       " ('dataset', 7),\n",
       " ('graphx', 7),\n",
       " ('implementation', 6),\n",
       " ('scala', 6),\n",
       " ('developers', 6),\n",
       " ('including', 6),\n",
       " ('simple', 6),\n",
       " ('pipelines', 6),\n",
       " ('batch', 6),\n",
       " ('abstraction', 6),\n",
       " ('map', 6),\n",
       " ('two', 6),\n",
       " ('big', 6),\n",
       " ('graphs', 6),\n",
       " ('analytics', 5),\n",
       " ('even', 5),\n",
       " ('computing', 5),\n",
       " ('java', 5),\n",
       " ('parallel', 5),\n",
       " ('set', 5),\n",
       " ('applications', 5),\n",
       " ('using', 5),\n",
       " ('top', 5),\n",
       " ('across', 5),\n",
       " ('supports', 5),\n",
       " ('system', 5),\n",
       " ('new', 5),\n",
       " ('these', 5),\n",
       " ('project', 5),\n",
       " ('much', 5),\n",
       " ('writing', 5),\n",
       " ('function', 4),\n",
       " ('multiple', 4),\n",
       " ('custom', 4),\n",
       " ('well', 4),\n",
       " ('process', 4),\n",
       " ('immutable', 4),\n",
       " ('advantage', 4),\n",
       " ('engine', 4),\n",
       " ('times', 4),\n",
       " ('a', 4),\n",
       " ('dataframes', 4),\n",
       " ('like', 4),\n",
       " ('required', 4),\n",
       " ('models', 4),\n",
       " ('perform', 4),\n",
       " ('r', 4),\n",
       " ('separate', 4),\n",
       " ('foundation', 4),\n",
       " ('nodes', 4),\n",
       " ('continuous', 4),\n",
       " ('one', 4),\n",
       " ('queries', 4),\n",
       " ('file', 4),\n",
       " ('large', 4),\n",
       " ('dataframe', 3),\n",
       " ('restricted', 3),\n",
       " ('single', 3),\n",
       " ('languages', 3),\n",
       " ('minibatches', 3),\n",
       " ('thus', 3),\n",
       " ('based', 3),\n",
       " ('higherlevel', 3),\n",
       " ('cloud', 3),\n",
       " ('frameworks', 3),\n",
       " ('driver', 3),\n",
       " ('databricks', 3),\n",
       " ('standard', 3),\n",
       " ('important', 3),\n",
       " ('lines', 3),\n",
       " ('stores', 3),\n",
       " ('different', 3),\n",
       " ('needs', 3),\n",
       " ('realtime', 3),\n",
       " ('storm', 3),\n",
       " ('2x', 3),\n",
       " ('originally', 3),\n",
       " ('method', 3),\n",
       " ('structure', 3),\n",
       " ('programs', 3),\n",
       " ('offers', 3),\n",
       " ('amazon', 3),\n",
       " ('mode', 3),\n",
       " ('reduce', 3),\n",
       " ('take', 3),\n",
       " ('this', 3),\n",
       " ('world', 3),\n",
       " ('jobs', 3),\n",
       " ('but', 3),\n",
       " ('you', 3),\n",
       " ('dag', 3),\n",
       " ('approach', 3),\n",
       " ('become', 3),\n",
       " ('comes', 3),\n",
       " ('concept', 3),\n",
       " ('apis', 3),\n",
       " ('disk', 3),\n",
       " ('jvm', 3),\n",
       " ('fast', 3),\n",
       " ('part', 3),\n",
       " ('users', 3),\n",
       " ('however', 3),\n",
       " ('running', 3),\n",
       " ('clustering', 3),\n",
       " ('makes', 3),\n",
       " ('supported', 3),\n",
       " ('amplab', 3),\n",
       " ('scheduling', 3),\n",
       " ('program', 3),\n",
       " ('allowing', 3),\n",
       " ('storage', 3),\n",
       " ('many', 3),\n",
       " ('clusters', 2),\n",
       " ('later', 2),\n",
       " ('items', 2),\n",
       " ('training', 2),\n",
       " ('native', 2),\n",
       " ('variety', 2),\n",
       " ('input', 2),\n",
       " ('ones', 2),\n",
       " ('sequence', 2),\n",
       " ('available', 2),\n",
       " ('besides', 2),\n",
       " ('functional', 2),\n",
       " ('called', 2),\n",
       " ('net16', 2),\n",
       " ('builtin', 2),\n",
       " ('event', 2),\n",
       " ('latency', 2),\n",
       " ('technology', 2),\n",
       " ('due', 2),\n",
       " ('mahout', 2),\n",
       " ('software', 2),\n",
       " ('key', 2),\n",
       " ('power', 2),\n",
       " ('sets', 2),\n",
       " ('deployed', 2),\n",
       " ('microsoft', 2),\n",
       " ('distributions', 2),\n",
       " ('kubernetes', 2),\n",
       " ('solution', 2),\n",
       " ('enterprise', 2),\n",
       " ('require', 2),\n",
       " ('at', 2),\n",
       " ('work', 2),\n",
       " ('likely', 2),\n",
       " ('easy', 2),\n",
       " ('package', 2),\n",
       " ('microbatching', 2),\n",
       " ('response', 2),\n",
       " ('as', 2),\n",
       " ('maintained', 2),\n",
       " ('resilient', 2),\n",
       " ('results', 2),\n",
       " ('may', 2),\n",
       " ('reduced', 2),\n",
       " ('management', 2),\n",
       " ('requires', 2),\n",
       " ('testing', 2),\n",
       " ('execution', 2),\n",
       " ('shared', 2),\n",
       " ('variables', 2),\n",
       " ('common', 2),\n",
       " ('files', 2),\n",
       " ('transformations', 2),\n",
       " ('datasets', 2),\n",
       " ('implementations', 2),\n",
       " ('implemented', 2),\n",
       " ('need', 2),\n",
       " ('pagerank', 2),\n",
       " ('diskbased', 2),\n",
       " ('either', 2),\n",
       " ('companies', 2),\n",
       " ('find', 2),\n",
       " ('form', 2),\n",
       " ('managed', 2),\n",
       " ('completely', 2),\n",
       " ('inmemory', 2),\n",
       " ('components', 2),\n",
       " ('split', 2),\n",
       " ('s3', 2),\n",
       " ('among', 2),\n",
       " ('executor', 2),\n",
       " ('box', 2),\n",
       " ('cassandra', 2),\n",
       " ('mongodb', 2),\n",
       " ('reducing', 2),\n",
       " ('lowlatency', 2),\n",
       " ('rather', 2),\n",
       " ('case', 2),\n",
       " ('catalyst', 2),\n",
       " ('manner', 2),\n",
       " ('platform', 2),\n",
       " ('incoming', 2),\n",
       " ('developed', 2),\n",
       " ('donated', 2),\n",
       " ('readonly', 2),\n",
       " ('iterative', 2),\n",
       " ('querying', 2),\n",
       " ('compared', 2),\n",
       " ('basic', 2),\n",
       " ('objects', 2),\n",
       " ('example', 2),\n",
       " ('performs', 2),\n",
       " ('words', 2),\n",
       " ('language', 2),\n",
       " ('component', 2),\n",
       " ('traditional', 2),\n",
       " ('takes', 2),\n",
       " ('executors', 2),\n",
       " ('development', 2),\n",
       " ('io', 2),\n",
       " ('unified', 2),\n",
       " ('paradigm', 2),\n",
       " ('faster', 2),\n",
       " ('stages', 2),\n",
       " ('executed', 2),\n",
       " ('classification', 2),\n",
       " ('libraries', 2),\n",
       " ('google', 2),\n",
       " ('optimizer', 2),\n",
       " ('added', 2),\n",
       " ('still', 2),\n",
       " ('works', 2),\n",
       " ('berkeley', 2),\n",
       " ('analysis', 2),\n",
       " ('for', 2),\n",
       " ('manager', 2),\n",
       " ('provided', 2),\n",
       " ('standalone', 2),\n",
       " ('functions', 2),\n",
       " ('text', 2),\n",
       " ('written', 2),\n",
       " ('scale', 2),\n",
       " ('uc', 2),\n",
       " ('built', 2),\n",
       " ('creating', 2),\n",
       " ('modeling', 2),\n",
       " ('stream', 2),\n",
       " ('microbatches', 2),\n",
       " ('pipeline', 2),\n",
       " ('launch', 2),\n",
       " ('mesos', 2),\n",
       " ('yarn', 2),\n",
       " ('local', 2),\n",
       " ('include', 2),\n",
       " ('other', 2),\n",
       " ('performance', 2),\n",
       " ('vs', 2),\n",
       " ('could', 2),\n",
       " ('filtering', 2),\n",
       " ('allows', 2),\n",
       " ('codebase', 1),\n",
       " ('implicit', 1),\n",
       " ('opensource', 1),\n",
       " ('since', 1),\n",
       " ('university', 1),\n",
       " ('1x', 1),\n",
       " ('limitations', 1),\n",
       " ('particular', 1),\n",
       " ('store', 1),\n",
       " ('memory8', 1),\n",
       " ('magnitude', 1),\n",
       " ('manually', 1),\n",
       " ('kudu', 1),\n",
       " ('usually', 1),\n",
       " ('nonjvm', 1),\n",
       " ('broadcast', 1),\n",
       " ('forms', 1),\n",
       " ('style', 1),\n",
       " ('argument', 1),\n",
       " ('each', 1),\n",
       " ('following', 1),\n",
       " ('item', 1),\n",
       " ('occurring', 1),\n",
       " ('commandline', 1),\n",
       " ('compiletime', 1),\n",
       " ('dsl', 1),\n",
       " ('manipulate', 1),\n",
       " ('kinesis', 1),\n",
       " ('minibatch', 1),\n",
       " ('tcpip', 1),\n",
       " ('zeromq', 1),\n",
       " ('center', 1),\n",
       " ('benchmarks', 1),\n",
       " ('memorybased', 1),\n",
       " ('shipped', 1),\n",
       " ('alone', 1),\n",
       " ('attached', 1),\n",
       " ('edges', 1),\n",
       " ('full', 1),\n",
       " ('mapreducestyle', 1),\n",
       " ('transactional', 1),\n",
       " ('abstracts', 1),\n",
       " ('away', 1),\n",
       " ('distribute', 1),\n",
       " ('grunt', 1),\n",
       " ('marshalling', 1),\n",
       " ('qualities', 1),\n",
       " ('quickly', 1),\n",
       " ('shoulders', 1),\n",
       " ('apple', 1),\n",
       " ('ways', 1),\n",
       " ('fundamental', 1),\n",
       " ('mediate', 1),\n",
       " ('necessary', 1),\n",
       " ('worker', 1),\n",
       " ('demand', 1),\n",
       " ('mean', 1),\n",
       " ('out', 1),\n",
       " ('robust', 1),\n",
       " ('swarm', 1),\n",
       " ('distribution', 1),\n",
       " ('founders', 1),\n",
       " ('integrated', 1),\n",
       " ('included', 1),\n",
       " ('report', 1),\n",
       " ('contained', 1),\n",
       " ('creates', 1),\n",
       " ('efficiently', 1),\n",
       " ('situations', 1),\n",
       " ('friendliness', 1),\n",
       " ('second', 1),\n",
       " ('comparison', 1),\n",
       " ('complexity', 1),\n",
       " ('count', 1),\n",
       " ('collection', 1),\n",
       " ('aggregation', 1),\n",
       " ('buckets', 1),\n",
       " ('functionality', 1),\n",
       " ('joining', 1),\n",
       " ('nosql', 1),\n",
       " ('bringing', 1),\n",
       " ('known', 1),\n",
       " ('shark', 1),\n",
       " ('connectors', 1),\n",
       " ('line', 1),\n",
       " ('imported', 1),\n",
       " ('javabased', 1),\n",
       " ('kmeans', 1),\n",
       " ('scientists', 1),\n",
       " ('swapped', 1),\n",
       " ('networks', 1),\n",
       " ('neural', 1),\n",
       " ('gain', 1),\n",
       " ('involving', 1),\n",
       " ('obviously', 1),\n",
       " ('would', 1),\n",
       " ('wins', 1),\n",
       " ('match', 1),\n",
       " ('create', 1),\n",
       " ('eventtime', 1),\n",
       " ('go', 1),\n",
       " ('messages', 1),\n",
       " ('streams', 1),\n",
       " ('handle', 1),\n",
       " ('latencies', 1),\n",
       " ('low', 1),\n",
       " ('scheme', 1),\n",
       " ('porting', 1),\n",
       " ('construct', 1),\n",
       " ('tensorflow', 1),\n",
       " ('tutorials', 1),\n",
       " ('basics', 1),\n",
       " ('guides', 1),\n",
       " ('heitman', 1),\n",
       " ('increasingly', 1),\n",
       " ('neanderthal', 1),\n",
       " ('science', 1),\n",
       " ('scientist', 1),\n",
       " ('california', 1),\n",
       " ('entire', 1),\n",
       " ('api67', 1),\n",
       " ('faulttolerant', 1),\n",
       " ('followed', 1),\n",
       " ('primary', 1),\n",
       " ('dataflow', 1),\n",
       " ('read', 1),\n",
       " ('reduction', 1),\n",
       " ('databasestyle', 1),\n",
       " ('ie', 1),\n",
       " ('repeated', 1),\n",
       " ('impetus', 1),\n",
       " ('spark10', 1),\n",
       " ('possible', 1),\n",
       " ('alluxio', 1),\n",
       " ('hdfs12', 1),\n",
       " ('openstack', 1),\n",
       " ('purposes', 1),\n",
       " ('centered', 1),\n",
       " ('exposed', 1),\n",
       " ('achieved', 1),\n",
       " ('faulttolerance', 1),\n",
       " ('functionalhigherorder', 1),\n",
       " ('net', 1),\n",
       " ('produce', 1),\n",
       " ('schedules', 1),\n",
       " ('reductions', 1),\n",
       " ('reducebykey', 1),\n",
       " ('transform', 1),\n",
       " ('dataframesa', 1),\n",
       " ('odbcjdbc', 1),\n",
       " ('server', 1),\n",
       " ('typed', 1),\n",
       " ('architecture1920', 1),\n",
       " ('design', 1),\n",
       " ('convenience', 1),\n",
       " ('engines', 1),\n",
       " ('according', 1),\n",
       " ('alternating', 1),\n",
       " ('done', 1),\n",
       " ('simplifies', 1),\n",
       " ('statistical', 1),\n",
       " ('graphprocessing', 1),\n",
       " ('bagel', 1),\n",
       " ('let', 1),\n",
       " ('predecessor', 1),\n",
       " ('unsuitable', 1),\n",
       " ('updated', 1),\n",
       " ('burdens', 1),\n",
       " ('tools', 1),\n",
       " ('worlds', 1),\n",
       " ('banks', 1),\n",
       " ('beginnings', 1),\n",
       " ('games', 1),\n",
       " ('governments', 1),\n",
       " ('consists', 1),\n",
       " ('converts', 1),\n",
       " ('some', 1),\n",
       " ('care', 1),\n",
       " ('hortonworks', 1),\n",
       " ('normally', 1),\n",
       " ('want', 1),\n",
       " ('azure', 1),\n",
       " ('company', 1),\n",
       " ('comprehensive', 1),\n",
       " ('hdinsight', 1),\n",
       " ('notebook', 1),\n",
       " ('builds', 1),\n",
       " ('why', 1),\n",
       " ('pointing', 1),\n",
       " ('prominence', 1),\n",
       " ('10', 1),\n",
       " ('around', 1),\n",
       " ('certain', 1),\n",
       " ('essence', 1),\n",
       " ('hundred', 1),\n",
       " ('multistage', 1),\n",
       " ('particularly', 1),\n",
       " ('state', 1),\n",
       " ('hiding', 1),\n",
       " ('represents', 1),\n",
       " ('combining', 1),\n",
       " ('commonly', 1),\n",
       " ('datastores', 1),\n",
       " ('ecosystem', 1),\n",
       " ('popular', 1),\n",
       " ('pulling', 1),\n",
       " ('random', 1),\n",
       " ('selections', 1),\n",
       " ('techniques', 1),\n",
       " ('trained', 1),\n",
       " ('details', 1),\n",
       " ('infoworld', 1),\n",
       " ('graphframes', 1),\n",
       " ('codebases', 1),\n",
       " ('something', 1),\n",
       " ('sync', 1),\n",
       " ('write', 1),\n",
       " ('breaking', 1),\n",
       " ('share', 1),\n",
       " ('able', 1),\n",
       " ('concerning', 1),\n",
       " ('delivery', 1),\n",
       " ('essentially', 1),\n",
       " ('points', 1),\n",
       " ('solves', 1),\n",
       " ('1ms', 1),\n",
       " ('experimental', 1),\n",
       " ('while', 1),\n",
       " ('continue', 1),\n",
       " ('statements', 1),\n",
       " ('guide', 1),\n",
       " ('ready', 1),\n",
       " ('largescale', 1),\n",
       " ('parallelism', 1),\n",
       " ('architectural', 1),\n",
       " ('machines', 1),\n",
       " ('multiset', 1),\n",
       " ('released', 1),\n",
       " ('though', 1),\n",
       " ('underlies', 1),\n",
       " ('deliberately', 1),\n",
       " ('algorithm', 1),\n",
       " ('interactiveexploratory', 1),\n",
       " ('loop', 1),\n",
       " ('class', 1),\n",
       " ('developing', 1),\n",
       " ('systems', 1),\n",
       " ('install', 1),\n",
       " ('11', 1),\n",
       " ('cpu', 1),\n",
       " ('instead', 1),\n",
       " ('maprfs13', 1),\n",
       " ('swift', 1),\n",
       " ('dispatching', 1),\n",
       " ('julia17', 1),\n",
       " ('task', 1),\n",
       " ('additional', 1),\n",
       " ('cluster2', 1),\n",
       " ('mirrors', 1),\n",
       " ('track', 1),\n",
       " ('type', 1),\n",
       " ('imperative', 1),\n",
       " ('anonymous', 1),\n",
       " ('frequencies', 1),\n",
       " ('pair', 1),\n",
       " ('rddcentric', 1),\n",
       " ('typical', 1),\n",
       " ('domainspecific', 1),\n",
       " ('interfaces', 1),\n",
       " ('uses', 1),\n",
       " ('equal', 1),\n",
       " ('flink21', 1),\n",
       " ('twitter', 1),\n",
       " ('onpremises', 1),\n",
       " ('architecture', 1),\n",
       " ('better', 1),\n",
       " ('gained', 1),\n",
       " ('machinelearning', 1),\n",
       " ('api27', 1),\n",
       " ('because', 1),\n",
       " ('database26', 1),\n",
       " ('deprecated', 1),\n",
       " ('vertices28', 1),\n",
       " ('mapreduce29', 1),\n",
       " ('initially', 1),\n",
       " ('crunch', 1),\n",
       " ('easytouse', 1),\n",
       " ('massive', 1),\n",
       " ('tandem', 1),\n",
       " ('giants', 1),\n",
       " ('tech', 1),\n",
       " ('assigned', 1),\n",
       " ('level', 1),\n",
       " ('allocating', 1),\n",
       " ('docker', 1),\n",
       " ('workers', 1),\n",
       " ('dataproc', 1),\n",
       " ('emr', 1),\n",
       " ('seek', 1),\n",
       " ('acyclic', 1),\n",
       " ('commands', 1),\n",
       " ('brought', 1),\n",
       " ('choice', 1),\n",
       " ('misnomer', 1),\n",
       " ('old', 1),\n",
       " ('overtaking', 1),\n",
       " ('worth', 1),\n",
       " ('5g', 1),\n",
       " ('cio', 1),\n",
       " ('consisting', 1),\n",
       " ('mapping', 1),\n",
       " ('means', 1),\n",
       " ('speed', 1),\n",
       " ('within', 1),\n",
       " ('developerfriendly', 1),\n",
       " ('50', 1),\n",
       " ('leading', 1),\n",
       " ('created', 1),\n",
       " ('runs', 1),\n",
       " ('borrowed', 1),\n",
       " ('pandas', 1),\n",
       " ('sql2003compliant', 1),\n",
       " ('suggests', 1),\n",
       " ('today', 1),\n",
       " ('json', 1),\n",
       " ('orc', 1),\n",
       " ('parquet', 1),\n",
       " ('reading', 1),\n",
       " ('columns', 1),\n",
       " ('applying', 1),\n",
       " ('ease', 1),\n",
       " ('feature', 1),\n",
       " ('forests', 1),\n",
       " ('includes', 1),\n",
       " ('production', 1),\n",
       " ('covers', 1),\n",
       " ('facilities', 1),\n",
       " ('regression', 1),\n",
       " ('selection', 1),\n",
       " ('domain', 1),\n",
       " ('helped', 1),\n",
       " ('requirements', 1),\n",
       " ('developer', 1),\n",
       " ('apex', 1),\n",
       " ('scenarios', 1),\n",
       " ('all', 1),\n",
       " ('dealing', 1),\n",
       " ('easier', 1),\n",
       " ('live', 1),\n",
       " ('query', 1),\n",
       " ('23', 1),\n",
       " ('relied', 1),\n",
       " ('future', 1),\n",
       " ('recommends', 1),\n",
       " ('lowerlevel', 1),\n",
       " ('udfs', 1),\n",
       " ('via', 1),\n",
       " ('article', 1),\n",
       " ('critical', 1),\n",
       " ('evan', 1),\n",
       " ('fault', 1),\n",
       " ('deprecated45', 1),\n",
       " ('encouraged3', 1),\n",
       " ('forces', 1),\n",
       " ('linear', 1),\n",
       " ('facilitates', 1),\n",
       " ('formed', 1),\n",
       " ('implementation29', 1),\n",
       " ('initial', 1),\n",
       " ('orders', 1),\n",
       " ('daemons', 1),\n",
       " ('scripts', 1),\n",
       " ('cassandra14', 1),\n",
       " ('system15', 1),\n",
       " ('contain', 1),\n",
       " ('invokes', 1),\n",
       " ('keeping', 1),\n",
       " ('lazy', 1),\n",
       " ('model', 1),\n",
       " ('passing', 1),\n",
       " ('applies', 1),\n",
       " ('computes', 1),\n",
       " ('flatmap', 1),\n",
       " ('operation', 1),\n",
       " ('afforded', 1),\n",
       " ('introduced', 1),\n",
       " ('lack', 1),\n",
       " ('typechecking', 1),\n",
       " ('capability', 1),\n",
       " ('cores', 1),\n",
       " ('facilitating', 1),\n",
       " ('lambda', 1),\n",
       " ('duration', 1),\n",
       " ('kafka', 1),\n",
       " ('sockets22', 1),\n",
       " ('least', 1),\n",
       " ('nine', 1),\n",
       " ('vowpal', 1),\n",
       " ('16', 1),\n",
       " ('formally', 1),\n",
       " ('general', 1),\n",
       " ('massively', 1),\n",
       " ('unlike', 1),\n",
       " ('version', 1),\n",
       " ('berkeleys', 1),\n",
       " ('research', 1),\n",
       " ('started', 1),\n",
       " ('2009', 1),\n",
       " ('bindings', 1),\n",
       " ('from', 1),\n",
       " ('telecommunications', 1),\n",
       " ('execute', 1),\n",
       " ('resource', 1),\n",
       " ('simply', 1),\n",
       " ('found', 1),\n",
       " ('optimized', 1),\n",
       " ('webbased', 1),\n",
       " ('user', 1),\n",
       " ('advantages', 1),\n",
       " ('bit', 1),\n",
       " ('days', 1),\n",
       " ('download', 1),\n",
       " ('roadmap', 1),\n",
       " ('back', 1),\n",
       " ('counterpart', 1),\n",
       " ('first', 1),\n",
       " ('whereas', 1),\n",
       " ('speedup', 1),\n",
       " ('behind', 1),\n",
       " ('document', 1),\n",
       " ('friendly', 1),\n",
       " ('shown', 1),\n",
       " ('heart', 1),\n",
       " ('scalable', 1),\n",
       " ('databases', 1),\n",
       " ('distributes', 1),\n",
       " ('fashion', 1),\n",
       " ('processes', 1),\n",
       " ('analysts', 1),\n",
       " ('focused', 1),\n",
       " ('name', 1),\n",
       " ('alongside', 1),\n",
       " ('hive', 1),\n",
       " ('jdbc', 1),\n",
       " ('selecting', 1),\n",
       " ('bundles', 1),\n",
       " ('extraction', 1),\n",
       " ('saved', 1),\n",
       " ('scalabased', 1),\n",
       " ('review', 1),\n",
       " ('structures', 1),\n",
       " ('taking', 1),\n",
       " ('disparate', 1),\n",
       " ('early', 1),\n",
       " ('kept', 1),\n",
       " ('operational', 1),\n",
       " ('things', 1),\n",
       " ('traction', 1),\n",
       " ('everybody', 1),\n",
       " ('manipulated', 1),\n",
       " ('mostly', 1),\n",
       " ('operator', 1),\n",
       " ('way', 1),\n",
       " ('flink', 1),\n",
       " ('streamingcapable', 1),\n",
       " ('earlier', 1),\n",
       " ('especially', 1),\n",
       " ('infinite', 1),\n",
       " ('real', 1),\n",
       " ('considered', 1),\n",
       " ('team', 1),\n",
       " ('bearable', 1),\n",
       " ('building', 1),\n",
       " ('legacy', 1),\n",
       " ('lot', 1),\n",
       " ('applied', 1),\n",
       " ('apply', 1),\n",
       " ('classifiers', 1),\n",
       " ('existing', 1),\n",
       " ('registered', 1),\n",
       " ('userdefined', 1),\n",
       " ('highly', 1),\n",
       " ('perspective', 1),\n",
       " ('relatively', 1),\n",
       " ('sense', 1),\n",
       " ('terms', 1),\n",
       " ('tolerance', 1),\n",
       " ('way2', 1),\n",
       " ('2012', 1),\n",
       " ('working', 1),\n",
       " ('ms', 1),\n",
       " ('visit', 1),\n",
       " ('several', 1),\n",
       " ('lustre', 1),\n",
       " ('mapr', 1),\n",
       " ('per', 1),\n",
       " ('pseudodistributed', 1),\n",
       " ('scenario', 1),\n",
       " ('wide', 1),\n",
       " ('connect', 1),\n",
       " ('functionalities', 1),\n",
       " ('overall', 1),\n",
       " ('usable', 1),\n",
       " ('filter', 1),\n",
       " ('joins', 1),\n",
       " ('lineage', 1),\n",
       " ('loss', 1),\n",
       " ('produced', 1),\n",
       " ('reconstructed', 1),\n",
       " ('accumulators', 1),\n",
       " ('rddoriented', 1),\n",
       " ('reference', 1),\n",
       " ('style2', 1),\n",
       " ('prints', 1),\n",
       " ('variant', 1),\n",
       " ('20', 1),\n",
       " ('although', 1),\n",
       " ('fully', 1),\n",
       " ('semistructured', 1),\n",
       " ('strongly', 1),\n",
       " ('enables', 1),\n",
       " ('ingests', 1),\n",
       " ('consume', 1),\n",
       " ('flume', 1),\n",
       " ('penalty', 1),\n",
       " ('streaming23', 1),\n",
       " ('als', 1),\n",
       " ('scales', 1),\n",
       " ('squares', 1),\n",
       " ('wabbit24', 1),\n",
       " ('pregel', 1),\n",
       " ('properties', 1),\n",
       " ('property', 1),\n",
       " ('giraph', 1),\n",
       " ('utilized', 1),\n",
       " ('viewed', 1),\n",
       " ('computers', 1),\n",
       " ('facebook', 1),\n",
       " ('humble', 1),\n",
       " ('ibm', 1),\n",
       " ('major', 1),\n",
       " ('main', 1),\n",
       " ('cloudera', 1),\n",
       " ('employs', 1),\n",
       " ('if', 1),\n",
       " ('service', 1),\n",
       " ('determines', 1),\n",
       " ('directed', 1),\n",
       " ('layer', 1),\n",
       " ('memory', 1),\n",
       " ('tend', 1),\n",
       " ('twostage', 1),\n",
       " ('argue', 1),\n",
       " ('almost', 1),\n",
       " ('calls', 1),\n",
       " ('canonical', 1),\n",
       " ('enabling', 1),\n",
       " ('providing', 1),\n",
       " ('sampling', 1),\n",
       " ('scaled', 1),\n",
       " ('splits', 1),\n",
       " ('hbase', 1),\n",
       " ('hdfs', 1),\n",
       " ('others', 1),\n",
       " ('packages', 1),\n",
       " ('note', 1),\n",
       " ('see', 1),\n",
       " ('addition', 1),\n",
       " ('concerns', 1),\n",
       " ('despite', 1),\n",
       " ('environments', 1),\n",
       " ('leads', 1),\n",
       " ('near', 1),\n",
       " ('previously', 1),\n",
       " ('requiring', 1),\n",
       " ('resources', 1),\n",
       " ('extended', 1),\n",
       " ('overhead', 1),\n",
       " ('series', 1),\n",
       " ('criticism', 1),\n",
       " ('pure', 1),\n",
       " ('aggregations', 1),\n",
       " ('interactive', 1),\n",
       " ('late', 1),\n",
       " ('pain', 1),\n",
       " ('struggled', 1),\n",
       " ('24', 1),\n",
       " ('handling', 1),\n",
       " ('impressive', 1),\n",
       " ('responses', 1),\n",
       " ('maintaining', 1),\n",
       " ('call', 1),\n",
       " ('keras', 1),\n",
       " ('dive', 1),\n",
       " ('lays', 1),\n",
       " ('learn', 1),\n",
       " ('recommend', 1),\n",
       " ('we', 1)]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 183
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OViND9SFFTOd"
   },
   "source": [
    "Да, было бы проще все сделать иным кодом и в один проход, но целью было разобрать, как все это примерно работает под капотом на больших данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhK08F7hFjv_"
   },
   "source": [
    "**Домашнее задание**\n",
    "\n",
    "Посчитать количество рейтингов больше 4 для каждого фильма и вывести фильмы в порядке убывания количества этих оценок"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sPx9_0-wFlK-",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:45.499272Z",
     "start_time": "2024-09-25T23:53:44.011722Z"
    }
   },
   "source": [
    "with open('user_ratedmovies.dat', 'rb') as f:\n",
    "    data = f.readlines()\n",
    "headers = data[0].decode().split('\\t')[:3]\n",
    "data = [row.decode().split('\\t')[:3] for row in data[1:]]   "
   ],
   "outputs": [],
   "execution_count": 184
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8yWQm0zJegy",
    "outputId": "20c31439-a718-4e1d-a113-878243a6c132",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:45.521126Z",
     "start_time": "2024-09-25T23:53:45.516114Z"
    }
   },
   "source": [
    "headers"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userID', 'movieID', 'rating']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgDpQdAeRG5e",
    "outputId": "251f8369-b897-4465-bfae-93782a55c088",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:45.569298Z",
     "start_time": "2024-09-25T23:53:45.564755Z"
    }
   },
   "source": [
    "data[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['75', '3', '1']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ln4GFhQZH5tM",
    "outputId": "9d1b38ba-13a4-4a1e-bb33-f90b5a3e26f2",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:45.618834Z",
     "start_time": "2024-09-25T23:53:45.613080Z"
    }
   },
   "source": [
    "len(data)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855598"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzkqhk9MRL8P"
   },
   "source": [
    "Пишем map, shiffle и reduce + параллелим вычисления. Лучше задавать batch_size при распараллеливании, либо даже заранее все разбить на батчи, будет быстрее\n",
    "\n",
    "Также посмотрите на то, нет ли перекоса в данных после shuffle, можете попробовать использовать остаток от деления не простого hash, а ввести какую-то функию"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:45.674264Z",
     "start_time": "2024-09-25T23:53:45.669210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Зададим хэш-функцию с меньшим перекосом данных после shuffle\n",
    "\n",
    "import hashlib\n",
    "\n",
    "def new_hash(obj_to_hash: int):\n",
    "    encoded_obj = str(obj_to_hash).encode()\n",
    "    hash_16 = hashlib.md5(encoded_obj).hexdigest()\n",
    "    return int(hash_16 ,16)\n"
   ],
   "outputs": [],
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_1aUiwrJRK3W",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:45.704690Z",
     "start_time": "2024-09-25T23:53:45.697146Z"
    }
   },
   "source": [
    "def map_rating(row):\n",
    "    films_with_rating = [(int(row[1]), float(row[2]))]\n",
    "    return films_with_rating\n",
    "\n",
    "def create_chunks(shuffled_data):\n",
    "    result = {}\n",
    "    for idx, data in shuffled_data:\n",
    "        if idx in result:\n",
    "            result[idx].append(data)\n",
    "        else:\n",
    "            result[idx] = [data]\n",
    "    return list(result.items())\n",
    "\n",
    "def shuffle_rating(mapper_result, n_nodes=5):\n",
    "    shuffled_data = []\n",
    "    for key, value in mapper_result:\n",
    "        if value > 4:\n",
    "            shuffled_data.append((new_hash(key)%n_nodes, (key, value)))\n",
    "    shuffled_data = sorted(shuffled_data, key=lambda x: x[0])\n",
    "    chunks = create_chunks(shuffled_data)\n",
    "    return chunks\n",
    "\n",
    "def reduce_rating(map_row):\n",
    "    result = {}\n",
    "    for key, value in map_row:\n",
    "        if key in result:\n",
    "            result[key] += 1\n",
    "        elif key not in result:\n",
    "            result[key] = 1\n",
    "    return result\n",
    "\n",
    "def map_shuffle(row, n_nodes):\n",
    "    map_result = map_rating(row)\n",
    "    shuffle_result = shuffle_rating(map_result, n_nodes)\n",
    "    return shuffle_result"
   ],
   "outputs": [],
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KJdLsomDRyS0",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:51.062880Z",
     "start_time": "2024-09-25T23:53:45.721122Z"
    }
   },
   "source": [
    "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=1000) as parallel:\n",
    "    res = parallel(delayed(map_shuffle)(row, n_nodes) for row in data)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 3010 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=5)]: Done 8010 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=5)]: Done 15010 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=5)]: Done 22010 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=5)]: Done 31010 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=5)]: Done 40010 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=5)]: Done 51010 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=5)]: Done 62010 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=5)]: Done 75010 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=5)]: Done 88010 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=5)]: Done 103010 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=5)]: Done 118010 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=5)]: Done 135010 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=5)]: Done 152010 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=5)]: Done 171010 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=5)]: Done 190010 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=5)]: Done 211010 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=5)]: Done 232010 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=5)]: Done 255010 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=5)]: Done 278010 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=5)]: Done 303010 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=5)]: Done 328010 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=5)]: Done 355010 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=5)]: Done 382010 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=5)]: Done 411010 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=5)]: Done 440010 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=5)]: Done 471010 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=5)]: Done 502010 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=5)]: Done 535010 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=5)]: Done 568010 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=5)]: Done 603010 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=5)]: Done 638010 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=5)]: Done 675010 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=5)]: Done 712010 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=5)]: Done 751010 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=5)]: Done 790010 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=5)]: Done 831010 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=5)]: Done 855197 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=5)]: Done 855598 out of 855598 | elapsed:    5.2s finished\n"
     ]
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:51.343889Z",
     "start_time": "2024-09-25T23:53:51.077849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shuffle_stage = {i:[] for i in range(5)}\n",
    "for values in res:\n",
    "    values = dict(values)\n",
    "    for key in values.keys():\n",
    "        shuffle_stage[key].extend(values[key])"
   ],
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:51.363123Z",
     "start_time": "2024-09-25T23:53:51.358045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key in shuffle_stage.keys():\n",
    "    print(f'{key}: number of words = {len(shuffle_stage[key])}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: number of words = 32524\n",
      "1: number of words = 30107\n",
      "2: number of words = 32131\n",
      "3: number of words = 30973\n",
      "4: number of words = 34597\n"
     ]
    }
   ],
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SmKhm2eeRyVZ",
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:51.513354Z",
     "start_time": "2024-09-25T23:53:51.397047Z"
    }
   },
   "source": [
    "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
    "    res = parallel(delayed(reduce_rating)(shuffle_stage[key]) for key in shuffle_stage.keys())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:51.531271Z",
     "start_time": "2024-09-25T23:53:51.525445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = {}\n",
    "for partition in res:\n",
    "    for key in partition.keys():\n",
    "        if key in result:\n",
    "            result[key] += partition[key]\n",
    "        else:\n",
    "            result[key] = partition[key]"
   ],
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T23:53:51.576027Z",
     "start_time": "2024-09-25T23:53:51.558456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = []\n",
    "\n",
    "for x in sorted(result.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    output.append([x[0], x[1]])\n",
    "    print(x[0], x[1])\n",
    "\n",
    "# output"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2571 900\n",
      "318 887\n",
      "296 878\n",
      "2959 828\n",
      "4993 756\n",
      "7153 719\n",
      "5952 697\n",
      "858 690\n",
      "50 688\n",
      "2858 680\n"
     ]
    }
   ],
   "execution_count": 195
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed0nAHrDSMcX"
   },
   "source": [
    "После reduce все можно собрать в одном цикле как на семинаре\n",
    "\n",
    "В качестве ответа вывести топ 10 фильмов с наибольшим числом оценок более 4\n",
    "\n",
    "### Срок выполнения домашего задания - 23.09.2024"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
